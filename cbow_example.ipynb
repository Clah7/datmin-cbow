{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Bag of Words (CBOW)\n",
    "\n",
    "Sebelum kita membahas lebih dalam mengenai **Continuous Bag of Words (CBOW)**, penting untuk memahami bahwa komputer tidak dapat memahami kata-kata atau bahasa dengan cara yang sama seperti manusia. Kata-kata yang kita gunakan dalam percakapan sehari-hari harus diubah menjadi bentuk numerik agar dapat diproses oleh komputer. Proses ini dikenal sebagai representasi numerik atau *word embeddings*.\n",
    "\n",
    "---\n",
    "\n",
    "## Apa Itu Word2Vec?\n",
    "\n",
    "**Word2Vec** adalah salah satu teknik populer yang digunakan untuk menghasilkan representasi numerik dari kata-kata (*word embeddings*). Word2Vec tidak hanya mengubah kata menjadi angka, tetapi juga memastikan bahwa hubungan semantik antar kata tetap terjaga. Sebagai contoh, kata-kata yang memiliki arti serupa atau sering muncul dalam konteks yang sama (misalnya \"raja\" dan \"ratu\") akan memiliki representasi vektor yang mirip dalam ruang multidimensi.\n",
    "\n",
    "Word2Vec bekerja dengan prinsip bahwa *kata yang muncul dalam konteks yang serupa cenderung memiliki makna yang serupa*. Ada dua pendekatan utama dalam Word2Vec:\n",
    "\n",
    "### 1. Continuous Bag of Words (CBOW)\n",
    "Model ini memprediksi kata target berdasarkan kata-kata konteks di sekitarnya. Sebagai contoh, jika Anda memiliki kalimat:  \n",
    "\n",
    "> \"Saya suka belajar Python.\"\n",
    "\n",
    "Dengan *window size* 2, CBOW akan menggunakan kata-kata di sekitar (\"Saya\", \"suka\", \"Python\") untuk memprediksi kata target \"belajar.\"\n",
    "\n",
    "### 2. Skip-gram\n",
    "Model ini bekerja sebaliknya dari CBOW, yaitu memprediksi kata-kata konteks berdasarkan kata target. Menggunakan contoh yang sama, jika kata target adalah \"belajar,\" Skip-gram akan mencoba memprediksi kata-kata konteks seperti \"Saya,\" \"suka,\" dan \"Python.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Contoh Sederhana\n",
    "\n",
    "Misalkan Anda memiliki kalimat:\n",
    "\n",
    "> \"Kucing duduk di atas tikar.\"\n",
    "\n",
    "Untuk komputer memahami kata-kata ini, kita perlu mengubahnya menjadi angka. Langkah-langkahnya adalah sebagai berikut:\n",
    "\n",
    "### 1. Tokenisasi\n",
    "Pisahkan kalimat menjadi kata-kata individu:  \n",
    "`[\"Kucing\", \"duduk\", \"di\", \"atas\", \"tikar\"]`\n",
    "\n",
    "### 2. Pembuatan Vektor (One-Hot Encoding)\n",
    "Setiap kata diwakili oleh vektor biner dalam ruang kata:  \n",
    "Kucing -> [1, 0, 0, 0, 0] Duduk -> [0, 1, 0, 0, 0] Di -> [0, 0, 1, 0, 0] Atas -> [0, 0, 0, 1, 0] Tikar -> [0, 0, 0, 0, 1]\n",
    "\n",
    "\n",
    "Vektor ini memungkinkan komputer untuk mengenali hubungan antara kata-kata seperti \"kucing\" dan \"tikar\" (mungkin sering digunakan dalam konteks serupa).\n",
    "\n",
    "---\n",
    "\n",
    "## Mengapa Word2Vec Penting?\n",
    "\n",
    "Word2Vec memberikan cara yang efisien untuk menangkap makna semantik dan hubungan antar kata dalam teks. Dengan embedding yang dihasilkan:\n",
    "- Kata-kata yang semantik serupa seperti \"raja\" dan \"ratu\" akan memiliki vektor yang mirip.\n",
    "- Operasi matematika pada vektor dapat digunakan untuk menemukan hubungan antar kata, seperti:  \n",
    "\n",
    "Raja - Pria + Wanita ≈ Ratu\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Lambda\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"  # Pride and Prejudice\n",
    "response = requests.get(url)\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = cleaned_text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word2id = tokenizer.word_index\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id) + 1  # Include padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_target_pairs(sequences, window_size):\n",
    "    context_length = window_size * 2\n",
    "    pairs = []\n",
    "    for seq in sequences:\n",
    "        for idx, target in enumerate(seq):\n",
    "            start = max(idx - window_size, 0)\n",
    "            end = min(idx + window_size + 1, len(seq))\n",
    "            context = [seq[i] for i in range(start, end) if i != idx]\n",
    "            pairs.append((context, target))\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4\n",
    "pairs = generate_context_target_pairs(sequences, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = window_size * 2\n",
    "X = [pad_sequences([context], maxlen=context_length, padding='pre')[0] for context, _ in pairs]\n",
    "y = [to_categorical(target, num_classes=vocab_size) for _, target in pairs]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62813\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">720,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7202</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">727,402</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │       \u001b[38;5;34m720,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7202\u001b[0m)           │       \u001b[38;5;34m727,402\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,447,602</span> (5.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,447,602\u001b[0m (5.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,447,602</span> (5.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,447,602\u001b[0m (5.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(context_length,)),\n",
    "    Embedding(input_dim=vocab_size, output_dim=100, input_length=context_length),\n",
    "    Lambda(lambda x: K.mean(x, axis=1), output_shape=(100,)),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 11ms/step - accuracy: 0.0417 - loss: 6.8907\n",
      "Epoch 2/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.0673 - loss: 6.1552\n",
      "Epoch 3/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 11ms/step - accuracy: 0.0890 - loss: 5.8990\n",
      "Epoch 4/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.1152 - loss: 5.5984\n",
      "Epoch 5/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.1400 - loss: 5.3558\n",
      "Epoch 6/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.1580 - loss: 5.1527\n",
      "Epoch 7/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.1736 - loss: 4.9589\n",
      "Epoch 8/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.1897 - loss: 4.7951\n",
      "Epoch 9/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.2042 - loss: 4.6277\n",
      "Epoch 10/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 11ms/step - accuracy: 0.2154 - loss: 4.4995\n",
      "Epoch 11/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 11ms/step - accuracy: 0.2287 - loss: 4.3576\n",
      "Epoch 12/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 11ms/step - accuracy: 0.2395 - loss: 4.2243\n",
      "Epoch 13/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 11ms/step - accuracy: 0.2544 - loss: 4.0903\n",
      "Epoch 14/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 11ms/step - accuracy: 0.2655 - loss: 3.9715\n",
      "Epoch 15/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 12ms/step - accuracy: 0.2785 - loss: 3.8519\n",
      "Epoch 16/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 13ms/step - accuracy: 0.2915 - loss: 3.7417\n",
      "Epoch 17/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.2997 - loss: 3.6409\n",
      "Epoch 18/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.3134 - loss: 3.5333\n",
      "Epoch 19/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 13ms/step - accuracy: 0.3268 - loss: 3.4261\n",
      "Epoch 20/20\n",
      "\u001b[1m3975/3975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.3406 - loss: 3.3324\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (7202, 100)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "print(\"Embedding shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_words(word, embeddings, word2id, id2word, top_n=5):\n",
    "    if word not in word2id:\n",
    "        print(f\"Word '{word}' not found in vocabulary!\")\n",
    "        return\n",
    "    word_vector = embeddings[word2id[word]]\n",
    "    similarities = cosine_similarity([word_vector], embeddings)[0]\n",
    "    similar_indices = np.argsort(similarities)[-top_n-1:-1][::-1]\n",
    "    similar_words = [id2word[idx] for idx in similar_indices]\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'love': ['conjunction', 'swift', 'lot', 'servility', 'rejoice']\n"
     ]
    }
   ],
   "source": [
    "similar_words = find_similar_words(\"love\", embeddings, word2id, id2word)\n",
    "print(\"Words similar to 'love':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
